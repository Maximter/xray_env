{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas -q\n",
    "%pip install matplotlib -q\n",
    "%pip install kagglehub -q\n",
    "%pip install tensorflow -q\n",
    "%pip install scikit-learn -q\n",
    "%pip install seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:50:32.167650Z",
     "iopub.status.busy": "2025-05-28T20:50:32.167362Z",
     "iopub.status.idle": "2025-05-28T20:50:52.270652Z",
     "shell.execute_reply": "2025-05-28T20:50:52.269448Z",
     "shell.execute_reply.started": "2025-05-28T20:50:32.167627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D, GlobalAveragePooling2D, Dropout \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим данные\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# преднастройка формаирование датасета\n",
    "settings_loading_data = dict(\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb', # если использовать предобученную ч/б модель, то изменить этот параметр на 'grayscale'\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest', # Попробовать: bicubic (лучшая, но тяжёлая) lanczos3/5 (вроде норм)\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n",
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# сформируем датасеты\n",
    "df_train = image_dataset_from_directory(\n",
    "    path + '/chest_xray/train',\n",
    "    shuffle=True,\n",
    "    **settings_loading_data\n",
    ")\n",
    "\n",
    "df_valid = image_dataset_from_directory(\n",
    "    path + '/chest_xray/val',\n",
    "    shuffle=False,\n",
    "    **settings_loading_data\n",
    ")\n",
    "\n",
    "df_test = image_dataset_from_directory(\n",
    "    path + '/chest_xray/test',\n",
    "    shuffle=False,\n",
    "    **settings_loading_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "# вывод 9 фотографий из датасета для примера\n",
    "class_names = df_train.class_names\n",
    "print(\"Классы:\", class_names)\n",
    "\n",
    "# for images, labels in df_train.take(1):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\").squeeze(), cmap='gray') \n",
    "#         plt.title(f\"Class: {class_names[int(labels[i].numpy().item())]}\")\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новый размер train (батчей): 132\n",
      "Новый размер valid (батчей): 32\n"
     ]
    }
   ],
   "source": [
    "# т.к. 16 изображений валидационной выборки - это очень мало, то объединим test с val, а потом разобьем их\n",
    "df_train_full = df_train.concatenate(df_valid)\n",
    "val_size = int(len(df_train_full) * 0.2)\n",
    "\n",
    "df_valid = df_train_full.take(val_size)\n",
    "df_train = df_train_full.skip(val_size)\n",
    "\n",
    "print(f\"Новый размер train (батчей): {len(df_train)}\")\n",
    "print(f\"Новый размер valid (батчей): {len(df_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс NORMAL (0): 1067 изображений\n",
      "Класс PNEUMONIA (1): 3141 изображений\n"
     ]
    }
   ],
   "source": [
    "# проверим баланс классов\n",
    "# TODO - сделать попроще это ячейку\n",
    "labels = []\n",
    "for _, label_batch in df_train:\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "normal_count = np.sum(np.array(labels) == 0)\n",
    "pneumonia_count = np.sum(np.array(labels) == 1)\n",
    "\n",
    "print(f\"Класс NORMAL (0): {normal_count} изображений\")\n",
    "print(f\"Класс PNEUMONIA (1): {pneumonia_count} изображений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроим аугментацию\n",
    "# 1. будем поворачивать фотографии, на 10 градусов в разные стороны\n",
    "# 2. смещаем фотографии по вертикали и горизонатли на 10 процентов\n",
    "# 3. зумим фотографии на 20 процентов\n",
    "data_augmentation_pipeline = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(factor=10/360.0, fill_mode=\"nearest\", interpolation=\"bilinear\"),\n",
    "    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode=\"nearest\", interpolation=\"bilinear\"),\n",
    "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2, fill_mode=\"nearest\", interpolation=\"bilinear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#применим аугментацию\n",
    "def augment_and_preprocess_train(image, label):\n",
    "    image_augmented = data_augmentation_pipeline(image, training=True)\n",
    "\n",
    "    image_float_0_1 = tf.image.convert_image_dtype(image_augmented, tf.float32)\n",
    "    brightness_factor = tf.random.uniform(shape=[], minval=0.8, maxval=1.2)\n",
    "    image_brightened = image_float_0_1 * brightness_factor\n",
    "    image_brightened = tf.clip_by_value(image_brightened, 0.0, 1.0)\n",
    "\n",
    "    image_for_resnet_preprocess = image_brightened * 255.0\n",
    "    image_preprocessed = preprocess_input(image_for_resnet_preprocess) \n",
    "\n",
    "    return image_preprocessed, label\n",
    "\n",
    "def preprocess_val_test(image, label):\n",
    "    image = tf.cast(image, tf.float32) # Просто переводим в float32\n",
    "    image_preprocessed = preprocess_input(image) # И применяем ту же предобработку ResNet\n",
    "    return image_preprocessed, label\n",
    "\n",
    "\n",
    "df_train_processed = df_train.map(augment_and_preprocess_train, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "df_test_processed = df_test.map(preprocess_val_test, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "df_valid_processed = df_valid.map(preprocess_val_test, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,589,761</span> (89.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,589,761\u001b[0m (89.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,536,641</span> (89.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,536,641\u001b[0m (89.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# создадим модель\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "backbone = ResNet50(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(backbone)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=2e-4) \n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\n",
    "        'accuracy',       \n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс NORMAL (0): 1077 изображений\n",
      "Класс PNEUMONIA (1): 3131 изображений\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:25:37.716716: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# проверим баланс классов\n",
    "# TODO - сделать попроще это ячейку\n",
    "labels = []\n",
    "for _, label_batch in df_train_processed:\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "normal_count = np.sum(np.array(labels) == 0)\n",
    "pneumonia_count = np.sum(np.array(labels) == 1)\n",
    "\n",
    "print(f\"Класс NORMAL (0): {normal_count} изображений\")\n",
    "print(f\"Класс PNEUMONIA (1): {pneumonia_count} изображений\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем class_weights\n",
    "# сделаем это через кол-во элементов одного и второго класса\n",
    "labels = np.concatenate([y for x, y in df_train_processed], axis=0)\n",
    "normal_count = np.sum(labels == 0)\n",
    "pneumonia_count = np.sum(labels == 1)\n",
    "total_count = len(labels)\n",
    "\n",
    "weight_for_0 = (1 / normal_count) * (total_count / 2)\n",
    "weight_for_1 = (1 / pneumonia_count) * (total_count / 2)\n",
    "\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751268599.848719   12369 service.cc:152] XLA service 0x72e8e40388e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751268599.848755   12369 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2025-06-30 10:30:01.050397: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751268603.902387   12369 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1751268622.022025   12369 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.7833 - auc: 0.8276 - loss: 0.5396 - precision: 0.8997 - recall: 0.7987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 366ms/step - accuracy: 0.7834 - auc: 0.8278 - loss: 0.5394 - precision: 0.8998 - recall: 0.7989 - val_accuracy: 0.2920 - val_auc: 0.5465 - val_loss: 0.8041 - val_precision: 0.8276 - val_recall: 0.0323 - learning_rate: 2.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 194ms/step - accuracy: 0.8273 - auc: 0.8851 - loss: 0.4409 - precision: 0.9376 - recall: 0.8222 - val_accuracy: 0.2764 - val_auc: 0.5024 - val_loss: 1.1139 - val_precision: 1.0000 - val_recall: 0.0172 - learning_rate: 2.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8343 - auc: 0.8925 - loss: 0.4294 - precision: 0.9422 - recall: 0.8221\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 209ms/step - accuracy: 0.8343 - auc: 0.8926 - loss: 0.4292 - precision: 0.9422 - recall: 0.8222 - val_accuracy: 0.3008 - val_auc: 0.8107 - val_loss: 1.6671 - val_precision: 1.0000 - val_recall: 0.0402 - learning_rate: 2.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 197ms/step - accuracy: 0.8338 - auc: 0.9131 - loss: 0.3797 - precision: 0.9423 - recall: 0.8249 - val_accuracy: 0.3252 - val_auc: 0.3514 - val_loss: 0.8446 - val_precision: 0.6144 - val_recall: 0.1946 - learning_rate: 4.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8659 - auc: 0.9299 - loss: 0.3332 - precision: 0.9580 - recall: 0.8587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 202ms/step - accuracy: 0.8659 - auc: 0.9299 - loss: 0.3332 - precision: 0.9580 - recall: 0.8587 - val_accuracy: 0.4346 - val_auc: 0.3315 - val_loss: 0.7707 - val_precision: 0.6353 - val_recall: 0.5182 - learning_rate: 4.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8675 - auc: 0.9328 - loss: 0.3215 - precision: 0.9576 - recall: 0.8601"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 203ms/step - accuracy: 0.8674 - auc: 0.9328 - loss: 0.3216 - precision: 0.9576 - recall: 0.8601 - val_accuracy: 0.6895 - val_auc: 0.4353 - val_loss: 0.6567 - val_precision: 0.7212 - val_recall: 0.9342 - learning_rate: 4.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8615 - auc: 0.9233 - loss: 0.3436 - precision: 0.9578 - recall: 0.8513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 204ms/step - accuracy: 0.8615 - auc: 0.9233 - loss: 0.3435 - precision: 0.9578 - recall: 0.8514 - val_accuracy: 0.7236 - val_auc: 0.4925 - val_loss: 0.6480 - val_precision: 0.7273 - val_recall: 0.9906 - learning_rate: 4.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8583 - auc: 0.9331 - loss: 0.3330 - precision: 0.9554 - recall: 0.8456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 206ms/step - accuracy: 0.8583 - auc: 0.9330 - loss: 0.3331 - precision: 0.9554 - recall: 0.8456 - val_accuracy: 0.7168 - val_auc: 0.6090 - val_loss: 0.5923 - val_precision: 0.7315 - val_recall: 0.9665 - learning_rate: 4.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.8693 - auc: 0.9338 - loss: 0.3226 - precision: 0.9590 - recall: 0.8605 - val_accuracy: 0.7197 - val_auc: 0.3287 - val_loss: 0.8023 - val_precision: 0.7267 - val_recall: 0.9852 - learning_rate: 4.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8698 - auc: 0.9354 - loss: 0.3149 - precision: 0.9624 - recall: 0.8586\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 197ms/step - accuracy: 0.8697 - auc: 0.9354 - loss: 0.3150 - precision: 0.9623 - recall: 0.8586 - val_accuracy: 0.7236 - val_auc: 0.2570 - val_loss: 1.2708 - val_precision: 0.7234 - val_recall: 1.0000 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72e9b99abd70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем коллбэки\n",
    "# 1. Настройка learning rate при обучении\n",
    "# 2. Сохранение лучшей версии модели\n",
    "# 3. Остановка обучения, если нет улучшений\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    df_train_processed,\n",
    "    validation_data=df_valid_processed,\n",
    "    class_weight=class_weights,\n",
    "    epochs=10,\n",
    "    callbacks=[reduce_lr, model_checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.3457 - auc: 0.4773 - loss: 1.0327 - precision: 0.3038 - recall: 0.6598\n",
      "Test Loss: 0.6858784556388855\n",
      "Test Accuracy: 0.6330128312110901\n"
     ]
    }
   ],
   "source": [
    "# проверим модель на тесте\n",
    "results = model.evaluate(df_test_processed)\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "    ДО class_weights:\n",
    "    Test Loss: 0.6504877805709839\n",
    "    Test Accuracy: 0.6089743375778198\n",
    "\n",
    "    ПОСЛЕ class_weights:\n",
    "    Test Loss: 0.6858784556388855\n",
    "    Test Accuracy: 0.6330128312110901\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# сделаем матрицу ошибок\n",
    "y_pred_proba = model.predict(df_test_processed)\n",
    "y_pred = (y_pred_proba > 0.5).astype('int32')\n",
    "y_true = np.concatenate([y for x, y in df_test_processed], axis=0)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Предсказанные метки')\n",
    "plt.ylabel('Истинные метки')\n",
    "plt.title('Матрица ошибок')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "  ДО class_weights:\n",
    "  0 - 17 - 217\n",
    "  1 - 27 - 363\n",
    "    | 0  |  1 |\n",
    "\n",
    "  ПОСЛЕ class_weights:\n",
    "  0 - 11 - 223\n",
    "  1 - 6 - 384\n",
    "    | 0  |  1 |\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "xray_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
